Summary
Here's a brief summary of what you learnt in this session: 

Machine learning models can be classified into the following two categories on the basis of the learning algorithm:
	Supervised learning method: Past data with labels is available to build the model.
		Regression: The output variable is continuous in nature.
		Classification: The output variable is categorical in nature.
	Unsupervised learning method: Past data with labels is not available.
		Clustering: There is no predefined notion of labels.
Past dataset is divided into two parts in the supervised learning method: 
	Training data is used for the model to learn during modelling.
	Testing data is used by the trained model for prediction and model evaluation.
Linear regression models can be classified into two types depending upon the number of independent variables: 
	Simple linear regression: This is used when the number of independent variables is 1.
	Multiple linear regression: This is used when the number of independent variables is more than 1.
The equation of the best fit regression line Y = β₀ + β₁X can be found by minimising the cost function (RSS in this case, using the ordinary least squares method), which is done using the following two methods:
	Differentiation
	Gradient descent 
The strength of a linear regression model is mainly explained by R², where R² = 1 - (RSS/TSS).
	RSS: Residual sum of squares
	TSS: Total sum of squares

Summary
In this session, you build a simple linear regression model in Python using the advertising dataset. You also saw some more theoretical aspects in between. Here's a brief of what you learnt in this session.

A quick recap of simple linear regression
Assumptions of simple linear regression
	Linear relationship between X and y.
	Normal distribution of error terms.
	Independence of error terms.
	Constant variance of error terms.
Hypothesis testing in linear regression
	To determine the significance of beta coefficients.

Building a linear model
	OLS (Ordinary Least Squares) method in statsmodels to fit a line.
Summary statistics
	F-statistic, r-squared, coefficients and their p-values.
Residual Analysis
	Histogram of the error terms to check normality.
	Plot of the error terms with X or y to check independence.
Predictions
	Making predictions on the test set using the 'predict()' function.
Linear Regression using SKLearn
	A second package apart from statsmodels for linear regression.
	A more hassle-free package to just fit a line without any inferences.